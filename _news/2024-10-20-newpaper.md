---
layout: post
date: 2024-10-20 00:00:00-0400
inline: true
---

New papers building on VLMs: ðŸ“Ž [ProLIP](https://arxiv.org/abs/2410.05270) shows that adequately finetuning the last CLIP layer significantly boost few-shot classification. â˜• [LatteCLIP](https://arxiv.org/abs/2410.08211) proposes an unsupervised prototype-based CLIP finetuning from only synthetic labels.